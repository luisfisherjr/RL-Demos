{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/openai/gym/blob/5cb12296274020db9bb6378ce54276b31e7002da/gym/envs/__init__.py#L352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/tf-source-keras-gym/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale\n",
    "from skimage import io\n",
    "\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix neg reward to -1 , 0, or 1 orignal range is (-inf, inf)\n",
    "def transform_reward(reward):\n",
    "    return np.sign(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q(s, a) = r + γ maxₐ’(Q(s’, a’))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_batch(model, gamma, start_states, actions, rewards, next_states, is_terminal):\n",
    "    \"\"\"Do one deep Q learning iteration.\n",
    "    \n",
    "    Params:\n",
    "    - model: The DQN\n",
    "    - gamma: Discount factor (should be 0.99)\n",
    "    - start_states: numpy array of starting states\n",
    "    - actions: numpy array of one-hot encoded actions corresponding to the start states\n",
    "    - rewards: numpy array of rewards corresponding to the start states and actions\n",
    "    - next_states: numpy array of the resulting states corresponding to the start states and actions\n",
    "    - is_terminal: numpy boolean array of whether the resulting state is terminal\n",
    "    \n",
    "    \"\"\"\n",
    "    # First, predict the Q values of the next states. Note how we are passing ones as the mask.\n",
    "    next_Q_values = model.predict([next_states, np.ones(actions.shape)])\n",
    "    # The Q values of the terminal states is 0 by definition, so override them\n",
    "    next_Q_values[is_terminal] = 0\n",
    "    # The Q values of each start state is the reward + gamma * the max next state Q value\n",
    "    Q_values = rewards + gamma * np.max(next_Q_values, axis=1)\n",
    "    # Fit the keras model. Note how we are passing the actions as the mask and multiplying\n",
    "    # the targets by the actions.\n",
    "    model.fit(\n",
    "        [start_states, actions], actions * Q_values[:, None],\n",
    "        nb_epoch=1, batch_size=len(start_states), verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def atari_model(n_actions):\n",
    "\n",
    "    ATARI_SHAPE = (105, 80, 4)\n",
    "\n",
    "    # With the functional API we need to define the inputs.\n",
    "    frames_input = keras.layers.Input(ATARI_SHAPE, name='frames')\n",
    "    actions_input = keras.layers.Input((n_actions,), name='mask')\n",
    "    \n",
    "    # \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "    conv_1 = keras.layers.convolutional.Convolution2D(\n",
    "        16, 8, 8, subsample=(4, 4), activation='relu'\n",
    "    )(frames_input)\n",
    "    # \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "    conv_2 = keras.layers.convolutional.Convolution2D(\n",
    "        32, 4, 4, subsample=(2, 2), activation='relu'\n",
    "    )(conv_1)\n",
    "    # Flattening the second convolutional layer.\n",
    "    conv_flattened = keras.layers.core.Flatten()(conv_2)\n",
    "    # \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "    hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "    # \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "    output = keras.layers.Dense(n_actions)(hidden)\n",
    "    # Finally, we multiply the output by the mask!\n",
    "    filtered_output = keras.layers.merge([output, actions_input], mode='mul')\n",
    "\n",
    "    model = keras.models.Model(input=[frames_input, actions_input], output=filtered_output)\n",
    "    optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "    model.compile(optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create downsampled grayscaled images range 0, 1\n",
    "def preprocess(img):\n",
    "    return rescale(image = rgb2gray(raw_frame), scale = .5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 39, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_frame[12:100, 11:50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/tf-source-keras-gym/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/luis/anaconda3/envs/tf-source-keras-gym/lib/python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04bbcaa208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a breakout environment\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "# Reset it, returns the starting frame\n",
    "frame = env.reset()\n",
    "# Render\n",
    "# env.render()\n",
    "\n",
    "# done = False\n",
    "# while not done:\n",
    " \n",
    "# Perform a random action, returns the new frame, reward and whether the game is over\n",
    "raw_frame, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "# crap image\n",
    "raw_frame = raw_frame[25:195, 0:210]\n",
    "\n",
    "# gray and rescale image\n",
    "rescaled_gray_cropped_frame = preprocess(cropped_frame)\n",
    "\n",
    "io.imshow(rescaled_gray_cropped_frame)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_iteration(env, model, state, iteration, memory):\n",
    "    # Choose epsilon based on the iteration\n",
    "    epsilon = get_epsilon_for_iteration(iteration)\n",
    "\n",
    "    # Choose the action \n",
    "    if random.random() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = choose_best_action(model, state)\n",
    "\n",
    "    # Play one game iteration (note: according to the next paper, you should actually play 4 times here)\n",
    "    new_frame, reward, is_done, _ = env.step(action)\n",
    "    memory.add(state, action, new_frame, reward, is_done)\n",
    "\n",
    "    # Sample and fit\n",
    "    batch = memory.sample_batch(32)\n",
    "    fit_batch(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-source-keras-gym]",
   "language": "python",
   "name": "conda-env-tf-source-keras-gym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
